
<!DOCTYPE html
  PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<html><head>
      <meta http-equiv="Content-Type" content="text/html; charset=utf-8">
   <!--
This HTML was auto-generated from MATLAB code.
To make changes, update the MATLAB code and republish this document.
      --><title>test_ipopt2</title><meta name="generator" content="MATLAB 9.8"><link rel="schema.DC" href="http://purl.org/dc/elements/1.1/"><meta name="DC.date" content="2020-09-10"><meta name="DC.source" content="test_ipopt2.m"><style type="text/css">
html,body,div,span,applet,object,iframe,h1,h2,h3,h4,h5,h6,p,blockquote,pre,a,abbr,acronym,address,big,cite,code,del,dfn,em,font,img,ins,kbd,q,s,samp,small,strike,strong,sub,sup,tt,var,b,u,i,center,dl,dt,dd,ol,ul,li,fieldset,form,label,legend,table,caption,tbody,tfoot,thead,tr,th,td{margin:0;padding:0;border:0;outline:0;font-size:100%;vertical-align:baseline;background:transparent}body{line-height:1}ol,ul{list-style:none}blockquote,q{quotes:none}blockquote:before,blockquote:after,q:before,q:after{content:'';content:none}:focus{outine:0}ins{text-decoration:none}del{text-decoration:line-through}table{border-collapse:collapse;border-spacing:0}

html { min-height:100%; margin-bottom:1px; }
html body { height:100%; margin:0px; font-family:Arial, Helvetica, sans-serif; font-size:10px; color:#000; line-height:140%; background:#fff none; overflow-y:scroll; }
html body td { vertical-align:top; text-align:left; }

h1 { padding:0px; margin:0px 0px 25px; font-family:Arial, Helvetica, sans-serif; font-size:1.5em; color:#d55000; line-height:100%; font-weight:normal; }
h2 { padding:0px; margin:0px 0px 8px; font-family:Arial, Helvetica, sans-serif; font-size:1.2em; color:#000; font-weight:bold; line-height:140%; border-bottom:1px solid #d6d4d4; display:block; }
h3 { padding:0px; margin:0px 0px 5px; font-family:Arial, Helvetica, sans-serif; font-size:1.1em; color:#000; font-weight:bold; line-height:140%; }

a { color:#005fce; text-decoration:none; }
a:hover { color:#005fce; text-decoration:underline; }
a:visited { color:#004aa0; text-decoration:none; }

p { padding:0px; margin:0px 0px 20px; }
img { padding:0px; margin:0px 0px 20px; border:none; }
p img, pre img, tt img, li img, h1 img, h2 img { margin-bottom:0px; }

ul { padding:0px; margin:0px 0px 20px 23px; list-style:square; }
ul li { padding:0px; margin:0px 0px 7px 0px; }
ul li ul { padding:5px 0px 0px; margin:0px 0px 7px 23px; }
ul li ol li { list-style:decimal; }
ol { padding:0px; margin:0px 0px 20px 0px; list-style:decimal; }
ol li { padding:0px; margin:0px 0px 7px 23px; list-style-type:decimal; }
ol li ol { padding:5px 0px 0px; margin:0px 0px 7px 0px; }
ol li ol li { list-style-type:lower-alpha; }
ol li ul { padding-top:7px; }
ol li ul li { list-style:square; }

.content { font-size:1.2em; line-height:140%; padding: 20px; }

pre, code { font-size:12px; }
tt { font-size: 1.2em; }
pre { margin:0px 0px 20px; }
pre.codeinput { padding:10px; border:1px solid #d3d3d3; background:#f7f7f7; }
pre.codeoutput { padding:10px 11px; margin:0px 0px 20px; color:#4c4c4c; }
pre.error { color:red; }

@media print { pre.codeinput, pre.codeoutput { word-wrap:break-word; width:100%; } }

span.keyword { color:#0000FF }
span.comment { color:#228B22 }
span.string { color:#A020F0 }
span.untermstring { color:#B20000 }
span.syscmd { color:#B28C00 }
span.typesection { color:#A0522D }

.footer { width:auto; padding:10px 0px; margin:25px 0px 0px; border-top:1px dotted #878787; font-size:0.8em; line-height:140%; font-style:italic; color:#878787; text-align:left; float:none; }
.footer p { margin:0px; }
.footer a { color:#878787; }
.footer a:hover { color:#878787; text-decoration:underline; }
.footer a:visited { color:#878787; }

table th { padding:7px 5px; text-align:left; vertical-align:middle; border: 1px solid #d6d4d4; font-weight:bold; }
table td { padding:7px 5px; text-align:left; vertical-align:top; border:1px solid #d6d4d4; }





  </style></head><body><div class="content"><pre class="codeinput"><span class="keyword">function</span> test_ipopt

  auxdata = {} ;

  options.lb = [ -Inf, -Inf ] ;  <span class="comment">% Lower bound on the variables.</span>
  options.ub = [  Inf, Inf ] ;  <span class="comment">% Upper bound on the variables.</span>

  <span class="comment">% The constraint functions are bounded to zero</span>
  options.cl = [ 0, 0, -Inf ]; <span class="comment">%  constraints</span>
  options.cu = [ Inf, Inf, 0];

  <span class="comment">% Set up the auxiliary data.</span>
  options.auxdata = auxdata ;

  <span class="comment">% Set the IPOPT options.</span>
  options.ipopt.jac_d_constant   = <span class="string">'no'</span>;
  options.ipopt.hessian_constant = <span class="string">'no'</span>;
  options.ipopt.mu_strategy      = <span class="string">'adaptive'</span>;
  options.ipopt.max_iter         = 400;
  options.ipopt.tol              = 1e-10;

  <span class="comment">% The callback functions.</span>
  funcs.objective         = @objective;
  funcs.constraints       = @constraints;
  funcs.gradient          = @gradient;
  funcs.jacobian          = @jacobian;
  funcs.jacobianstructure = @jacobianstructure;
  <span class="keyword">if</span> true
    options.ipopt.derivative_test = <span class="string">'first-order'</span>;
    funcs.hessian           = @hessian;
    funcs.hessianstructure  = @hessianstructure;
  <span class="keyword">else</span>
    options.ipopt.hessian_approximation      = <span class="string">'limited-memory'</span>;
    <span class="comment">%options.ipopt.limited_memory_update_type = 'bfgs' ; % {bfgs}, sr1 = 6; % {6}</span>
    <span class="comment">%options.ipopt.limited_memory_update_type = 'sr1' ;</span>
    options.ipopt.limited_memory_update_type = <span class="string">'bfgs'</span> ; <span class="comment">% {bfgs}, sr1 = 6; % {6}</span>
  <span class="keyword">end</span>

  <span class="comment">% Run IPOPT.</span>
  x0 = [-2, 1] ;

  tic
  [x, info] = ipopt_auxdata(x0,funcs,options);
  elapsed = toc ;

  info;

  x

<span class="keyword">end</span>
</pre><pre class="codeoutput">This is Ipopt version 3.13.2, running with linear solver mumps.
NOTE: Other linear solvers might be more efficient (see Ipopt documentation).

</pre><p>map the indices with the corresponding index in the spase matrix</p><pre class="codeinput"><span class="keyword">function</span> f = objective(x,auxdata)
  f = 100*(x(2)-x(1)^2)^2+(1-x(1))^2 ;
<span class="keyword">end</span>
</pre><pre class="codeoutput">
No errors detected by derivative checker.

Number of nonzeros in equality constraint Jacobian...:        0
Number of nonzeros in inequality constraint Jacobian.:        6
Number of nonzeros in Lagrangian Hessian.............:        3

</pre><pre class="codeoutput">iter    objective    inf_pr   inf_du lg(mu)  ||d||  lg(rg) alpha_du alpha_pr  ls
   0  9.0900000e+02 3.00e+00 3.08e+01   0.0 0.00e+00    -  0.00e+00 0.00e+00   0
</pre><pre class="codeoutput">   6r 2.3745017e+01 1.00e+00 1.00e+03   2.8 0.00e+00    -  0.00e+00 4.68e-07R  2
   7r 1.0302114e+01 1.07e+00 3.81e+02  -3.3 9.39e-01    -  9.66e-01 7.45e-01f  1
   8r 1.8839746e+01 9.99e-01 2.42e+02  -0.1 5.32e-01   2.0 7.20e-01 6.27e-01f  1
   9r 5.8068120e+01 8.51e-01 5.90e+02  -4.6 7.30e-01   2.4 2.66e-03 3.92e-01f  1
</pre><p>map the indices with the corresponding index in the spase matrix</p><pre class="codeinput"><span class="keyword">function</span> g = gradient(x,auxdata)
  g = [ 400*x(1)*(x(1)^2-x(2))+2*x(1)-2, <span class="keyword">...</span>
        200*(x(2)-x(1)^2) ] ;
<span class="keyword">end</span>

<span class="keyword">function</span> f = constraints(x,auxdata)
  f = zeros(3,1) ;
  f(1) = x(1)*x(2)-1 ; <span class="comment">% = 0</span>
  f(2) = x(1) + x(2)^2 ; <span class="comment">% &gt;= 0</span>
  f(3) = x(1) ;
<span class="keyword">end</span>

<span class="keyword">function</span> jac = jacobian(x,auxdata)
  jac = sparse([ x(2), x(1)   ; <span class="keyword">...</span>
                 1,    2*x(2) ; <span class="keyword">...</span>
                 1,    0 ]) ;
<span class="keyword">end</span>

<span class="keyword">function</span> jac = jacobianstructure(auxdata)
  jac = sparse(ones(3,2)) ;
<span class="keyword">end</span>

<span class="keyword">function</span> H = hessian(x, sigma, lambda, auxdata)
  H = sigma * [ 1200*x(1)^2-400*x(2)+2, 0 ; <span class="keyword">...</span>
                 -400*x(1)               200] ;
  H = H + lambda(1) * [ 0 0 ; 1 0 ] ;
  H = H + lambda(2) * [ 0 0 ; 0 2 ] ;
  H = sparse(H) ;
<span class="keyword">end</span>

<span class="keyword">function</span> H = hessianstructure(auxdata)
  H = sparse([ 1 0 ; 1 1]) ;
<span class="keyword">end</span>
</pre><pre class="codeoutput">Starting derivative checker for first derivatives.

Total number of variables............................:        2
                     variables with only lower bounds:        0
                variables with lower and upper bounds:        0
                     variables with only upper bounds:        0
Total number of equality constraints.................:        0
Total number of inequality constraints...............:        3
        inequality constraints with only lower bounds:        2
   inequality constraints with lower and upper bounds:        0
        inequality constraints with only upper bounds:        1

   1  8.6471657e+02 2.96e+00 9.44e+01  -6.2 1.38e+00    -  1.00e+00 1.50e-02f  1
   2  2.5908555e+01 1.01e+00 1.78e+02  -1.3 1.99e+00    -  1.00e+00 9.85e-01f  1
   3  2.3773410e+01 1.00e+00 2.05e+02  -0.0 2.18e+00    -  1.00e+00 1.00e-02h  1
   4  2.3770640e+01 1.00e+00 2.05e+04  -7.1 9.92e-01    -  1.00e+00 1.14e-04h  1
   5  2.3745017e+01 1.00e+00 2.18e+08   0.1 2.82e+00    -  1.00e+00 9.38e-05h  1
iter    objective    inf_pr   inf_du lg(mu)  ||d||  lg(rg) alpha_du alpha_pr  ls
  10  1.3773143e+02 5.24e-01 5.49e+00  -1.3 1.12e+00    -  1.59e-01 3.13e-01h  1
  11  5.1513883e+02 0.00e+00 5.63e+00  -0.1 5.76e-01    -  6.26e-01 1.00e+00h  1
  12  3.8061799e+02 0.00e+00 1.44e+00  -2.2 1.57e-01    -  1.00e+00 8.51e-01f  1
  13  3.6025745e+02 2.57e-04 5.36e-02  -3.0 9.83e-02    -  1.00e+00 1.00e+00f  1
  14  3.6038081e+02 0.00e+00 2.41e-05  -4.3 3.44e-03    -  9.99e-01 1.00e+00h  1
  15  3.6037976e+02 0.00e+00 9.40e-10 -10.2 1.93e-05    -  1.00e+00 1.00e+00h  1
  16  3.6037976e+02 0.00e+00 3.55e-15 -11.0 1.61e-09    -  1.00e+00 1.00e+00h  1

Number of Iterations....: 16

                                   (scaled)                 (unscaled)
Objective...............:   1.4978377489726494e+01    3.6037976240281944e+02
Dual infeasibility......:   3.5527136788005009e-15    8.5478291111940048e-14
Constraint violation....:   0.0000000000000000e+00    0.0000000000000000e+00
Complementarity.........:   1.0000010361026186e-11    2.4060024928629001e-10
Overall NLP error.......:   1.0000010361026186e-11    2.4060024928629001e-10


Number of objective function evaluations             = 19
Number of objective gradient evaluations             = 15
Number of equality constraint evaluations            = 0
Number of inequality constraint evaluations          = 19
Number of equality constraint Jacobian evaluations   = 0
Number of inequality constraint Jacobian evaluations = 18
Number of Lagrangian Hessian evaluations             = 16
Total CPU secs in IPOPT (w/o function evaluations)   =      0.084
Total CPU secs in NLP function evaluations           =      0.118

EXIT: Optimal Solution Found.

x =

  -0.792123217851298  -1.262429843570410

</pre><p class="footer"><br><a href="https://www.mathworks.com/products/matlab/">Published with MATLAB&reg; R2020a</a><br></p></div><!--
##### SOURCE BEGIN #####
function test_ipopt

  auxdata = {} ;

  options.lb = [ -Inf, -Inf ] ;  % Lower bound on the variables.
  options.ub = [  Inf, Inf ] ;  % Upper bound on the variables.

  % The constraint functions are bounded to zero
  options.cl = [ 0, 0, -Inf ]; %  constraints
  options.cu = [ Inf, Inf, 0];
  
  % Set up the auxiliary data.
  options.auxdata = auxdata ;
  
  % Set the IPOPT options.
  options.ipopt.jac_d_constant   = 'no';
  options.ipopt.hessian_constant = 'no';
  options.ipopt.mu_strategy      = 'adaptive';
  options.ipopt.max_iter         = 400;
  options.ipopt.tol              = 1e-10;
  
  % The callback functions.
  funcs.objective         = @objective;
  funcs.constraints       = @constraints;
  funcs.gradient          = @gradient;
  funcs.jacobian          = @jacobian;
  funcs.jacobianstructure = @jacobianstructure;
  if true
    options.ipopt.derivative_test = 'first-order';
    funcs.hessian           = @hessian;
    funcs.hessianstructure  = @hessianstructure;
  else
    options.ipopt.hessian_approximation      = 'limited-memory';
    %options.ipopt.limited_memory_update_type = 'bfgs' ; % {bfgs}, sr1 = 6; % {6}
    %options.ipopt.limited_memory_update_type = 'sr1' ;
    options.ipopt.limited_memory_update_type = 'bfgs' ; % {bfgs}, sr1 = 6; % {6}
  end

  % Run IPOPT.
  x0 = [-2, 1] ; 

  tic
  [x, info] = ipopt_auxdata(x0,funcs,options);
  elapsed = toc ;

  info;

  x

end

%%
% map the indices with the corresponding index in the spase matrix
function f = objective(x,auxdata)
  f = 100*(x(2)-x(1)^2)^2+(1-x(1))^2 ;
end

%% 
% map the indices with the corresponding index in the spase matrix
function g = gradient(x,auxdata)
  g = [ 400*x(1)*(x(1)^2-x(2))+2*x(1)-2, ...
        200*(x(2)-x(1)^2) ] ;
end

function f = constraints(x,auxdata)
  f = zeros(3,1) ;
  f(1) = x(1)*x(2)-1 ; % = 0
  f(2) = x(1) + x(2)^2 ; % >= 0
  f(3) = x(1) ;
end

function jac = jacobian(x,auxdata)
  jac = sparse([ x(2), x(1)   ; ...
                 1,    2*x(2) ; ...
                 1,    0 ]) ;
end

function jac = jacobianstructure(auxdata)
  jac = sparse(ones(3,2)) ;
end

function H = hessian(x, sigma, lambda, auxdata)
  H = sigma * [ 1200*x(1)^2-400*x(2)+2, 0 ; ...
                 -400*x(1)               200] ;
  H = H + lambda(1) * [ 0 0 ; 1 0 ] ;
  H = H + lambda(2) * [ 0 0 ; 0 2 ] ;
  H = sparse(H) ;
end

function H = hessianstructure(auxdata)
  H = sparse([ 1 0 ; 1 1]) ;
end

##### SOURCE END #####
--></body></html>