
<!DOCTYPE html
  PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<html><head>
      <meta http-equiv="Content-Type" content="text/html; charset=utf-8">
   <!--
This HTML was auto-generated from MATLAB code.
To make changes, update the MATLAB code and republish this document.
      --><title>test_ipopt</title><meta name="generator" content="MATLAB 9.8"><link rel="schema.DC" href="http://purl.org/dc/elements/1.1/"><meta name="DC.date" content="2020-09-10"><meta name="DC.source" content="test_ipopt.m"><style type="text/css">
html,body,div,span,applet,object,iframe,h1,h2,h3,h4,h5,h6,p,blockquote,pre,a,abbr,acronym,address,big,cite,code,del,dfn,em,font,img,ins,kbd,q,s,samp,small,strike,strong,sub,sup,tt,var,b,u,i,center,dl,dt,dd,ol,ul,li,fieldset,form,label,legend,table,caption,tbody,tfoot,thead,tr,th,td{margin:0;padding:0;border:0;outline:0;font-size:100%;vertical-align:baseline;background:transparent}body{line-height:1}ol,ul{list-style:none}blockquote,q{quotes:none}blockquote:before,blockquote:after,q:before,q:after{content:'';content:none}:focus{outine:0}ins{text-decoration:none}del{text-decoration:line-through}table{border-collapse:collapse;border-spacing:0}

html { min-height:100%; margin-bottom:1px; }
html body { height:100%; margin:0px; font-family:Arial, Helvetica, sans-serif; font-size:10px; color:#000; line-height:140%; background:#fff none; overflow-y:scroll; }
html body td { vertical-align:top; text-align:left; }

h1 { padding:0px; margin:0px 0px 25px; font-family:Arial, Helvetica, sans-serif; font-size:1.5em; color:#d55000; line-height:100%; font-weight:normal; }
h2 { padding:0px; margin:0px 0px 8px; font-family:Arial, Helvetica, sans-serif; font-size:1.2em; color:#000; font-weight:bold; line-height:140%; border-bottom:1px solid #d6d4d4; display:block; }
h3 { padding:0px; margin:0px 0px 5px; font-family:Arial, Helvetica, sans-serif; font-size:1.1em; color:#000; font-weight:bold; line-height:140%; }

a { color:#005fce; text-decoration:none; }
a:hover { color:#005fce; text-decoration:underline; }
a:visited { color:#004aa0; text-decoration:none; }

p { padding:0px; margin:0px 0px 20px; }
img { padding:0px; margin:0px 0px 20px; border:none; }
p img, pre img, tt img, li img, h1 img, h2 img { margin-bottom:0px; }

ul { padding:0px; margin:0px 0px 20px 23px; list-style:square; }
ul li { padding:0px; margin:0px 0px 7px 0px; }
ul li ul { padding:5px 0px 0px; margin:0px 0px 7px 23px; }
ul li ol li { list-style:decimal; }
ol { padding:0px; margin:0px 0px 20px 0px; list-style:decimal; }
ol li { padding:0px; margin:0px 0px 7px 23px; list-style-type:decimal; }
ol li ol { padding:5px 0px 0px; margin:0px 0px 7px 0px; }
ol li ol li { list-style-type:lower-alpha; }
ol li ul { padding-top:7px; }
ol li ul li { list-style:square; }

.content { font-size:1.2em; line-height:140%; padding: 20px; }

pre, code { font-size:12px; }
tt { font-size: 1.2em; }
pre { margin:0px 0px 20px; }
pre.codeinput { padding:10px; border:1px solid #d3d3d3; background:#f7f7f7; }
pre.codeoutput { padding:10px 11px; margin:0px 0px 20px; color:#4c4c4c; }
pre.error { color:red; }

@media print { pre.codeinput, pre.codeoutput { word-wrap:break-word; width:100%; } }

span.keyword { color:#0000FF }
span.comment { color:#228B22 }
span.string { color:#A020F0 }
span.untermstring { color:#B20000 }
span.syscmd { color:#B28C00 }
span.typesection { color:#A0522D }

.footer { width:auto; padding:10px 0px; margin:25px 0px 0px; border-top:1px dotted #878787; font-size:0.8em; line-height:140%; font-style:italic; color:#878787; text-align:left; float:none; }
.footer p { margin:0px; }
.footer a { color:#878787; }
.footer a:hover { color:#878787; text-decoration:underline; }
.footer a:visited { color:#878787; }

table th { padding:7px 5px; text-align:left; vertical-align:middle; border: 1px solid #d6d4d4; font-weight:bold; }
table td { padding:7px 5px; text-align:left; vertical-align:top; border:1px solid #d6d4d4; }





  </style></head><body><div class="content"><pre class="codeinput"><span class="comment">%#  NLP written by GAMS Convert at 06/20/02 11:29:54</span>
<span class="comment">%#</span>
<span class="comment">%#  Equation counts</span>
<span class="comment">%#     Total       E       G       L       N       X</span>
<span class="comment">%#         3       2       1       0       0       0</span>
<span class="comment">%#</span>
<span class="comment">%#  Variable counts</span>
<span class="comment">%#                 x       b       i     s1s     s2s      sc      si</span>
<span class="comment">%#     Total    cont  binary integer    sos1    sos2   scont    sint</span>
<span class="comment">%#         5       5       0       0       0       0       0       0</span>
<span class="comment">%#  FX     0       0       0       0       0       0       0       0</span>
<span class="comment">%#</span>
<span class="comment">%#  Nonzero counts</span>
<span class="comment">%#     Total   const      NL     DLL</span>
<span class="comment">%#        12       6       6       0</span>
<span class="comment">%#</span>
<span class="comment">%#  Reformualtion has removed 1 variable and 1 equation</span>
<span class="comment">%</span>
<span class="comment">%</span>
<span class="comment">%var x1 := 50, &gt;= 50, &lt;= 200;</span>
<span class="comment">%var x2 := 37.5, &gt;= 37.5, &lt;= 150;</span>
<span class="comment">%var x3 := 45, &gt;= 45, &lt;= 180;</span>
<span class="comment">%var x4;</span>
<span class="comment">%</span>
<span class="comment">%minimize obj: 0.00533*x1^2 + 11.669*x1 + 0.00889*x2^2 + 10.333*x2 + 0.00741*x3^</span>
<span class="comment">%              2 + 10.833*x3 + 653.1;</span>
<span class="comment">%</span>
<span class="comment">%subject to</span>
<span class="comment">%</span>
<span class="comment">%e2:  - (0.01*(0.0676*x1*x1 + 0.00953*x1*x2 - 0.00507*x1*x3 + 0.00953*x2*x1 +</span>
<span class="comment">%    0.0521*x2*x2 + 0.00901*x2*x3 - 0.00507*x3*x1 + 0.00901*x3*x2 + 0.0294*x3*x3</span>
<span class="comment">%    ) - 0.000766*x1 - 3.42e-5*x2 + 0.000189*x3) + x4 = 0.040357;</span>
<span class="comment">%</span>
<span class="comment">%e3:    x1 + x2 + x3 - x4 &gt;= 210;</span>

<span class="keyword">function</span> test_ipopt

  auxdata = {} ;

  options.lb = [ 50, 37.5, 45, -Inf ] ;  <span class="comment">% Lower bound on the variables.</span>
  options.ub = [ 200, 150, 180, Inf ] ;  <span class="comment">% Upper bound on the variables.</span>

  <span class="comment">% The constraint functions are bounded to zero</span>
  options.cl = [ 0, 0 ]; <span class="comment">%  constraints</span>
  options.cu = [ 0, Inf ];

  <span class="comment">% Set up the auxiliary data.</span>
  options.auxdata = auxdata ;

  <span class="comment">% Set the IPOPT options.</span>
  options.ipopt.jac_d_constant   = <span class="string">'no'</span>;
  options.ipopt.hessian_constant = <span class="string">'no'</span>;
  options.ipopt.mu_strategy      = <span class="string">'adaptive'</span>;
  options.ipopt.max_iter         = 400;
  options.ipopt.tol              = 1e-10;

  <span class="comment">% The callback functions.</span>
  funcs.objective         = @objective;
  funcs.constraints       = @constraints;
  funcs.gradient          = @gradient;
  funcs.jacobian          = @jacobian;
  funcs.jacobianstructure = @jacobianstructure;
  <span class="keyword">if</span> true
    funcs.hessian           = @hessian;
    funcs.hessianstructure  = @hessianstructure;
    options.ipopt.derivative_test = <span class="string">'second-order'</span>;
  <span class="keyword">else</span>
    options.ipopt.hessian_approximation      = <span class="string">'limited-memory'</span>;
    <span class="comment">%options.ipopt.limited_memory_update_type = 'bfgs' ; % {bfgs}, sr1 = 6; % {6}</span>
    <span class="comment">%options.ipopt.limited_memory_update_type = 'sr1' ;</span>
    options.ipopt.limited_memory_update_type = <span class="string">'bfgs'</span> ; <span class="comment">% {bfgs}, sr1 = 6; % {6}</span>
  <span class="keyword">end</span>

  <span class="comment">% Run IPOPT.</span>
  x0 = [50, 37.5, 45, 0] ;

  tic
  [x, info] = ipopt_auxdata(x0,funcs,options);
  elapsed = toc ;

  info;

  x

<span class="keyword">end</span>
</pre><pre class="codeoutput">This is Ipopt version 3.13.2, running with linear solver mumps.
NOTE: Other linear solvers might be more efficient (see Ipopt documentation).

</pre><p>map the indices with the corresponding index in the spase matrix</p><pre class="codeinput"><span class="keyword">function</span> f = objective(x,auxdata)
  f = 0.00533*x(1)^2 + 11.669*x(1) + <span class="keyword">...</span>
      0.00889*x(2)^2 + 10.333*x(2) + <span class="keyword">...</span>
      0.00741*x(3)^2 + 10.833*x(3) + 653.1 ;
<span class="keyword">end</span>
</pre><pre class="codeoutput">Starting derivative checker for second derivatives.

</pre><pre class="codeoutput">iter    objective    inf_pr   inf_du lg(mu)  ||d||  lg(rg) alpha_du alpha_pr  ls
   0  2.1677592e+03 7.62e+01 8.15e+00   0.0 0.00e+00    -  0.00e+00 0.00e+00   0
</pre><p>map the indices with the corresponding index in the spase matrix</p><pre class="codeinput"><span class="keyword">function</span> g = gradient(x,auxdata)
  g = [ 0.01066*x(1) + 11.669, 0.01778*x(2) + 10.333, 0.01482*x(3) + 10.833, 0 ] ;
<span class="keyword">end</span>

<span class="keyword">function</span> f = constraints(x,auxdata)
  f = zeros(2,1) ;
  f(1) = - (0.01*(0.0676*x(1)^2 + 0.00953*x(1)*x(2) - 0.00507*x(1)*x(3) + <span class="keyword">...</span>
                  0.00953*x(2)*x(1) + 0.0521*x(2)^2 + 0.00901*x(2)*x(3) - <span class="keyword">...</span>
                  0.00507*x(3)*x(1) + 0.00901*x(3)*x(2) + 0.0294*x(3)*x(3) ) <span class="keyword">...</span>
         - 0.000766*x(1) - 3.42e-5*x(2) + 0.000189*x(3)) + x(4) - 0.040357 ; <span class="comment">% = 0</span>
  f(2) = x(1) + x(2) + x(3) - x(4) - 210 ; <span class="comment">% &gt;= 0</span>
<span class="keyword">end</span>

<span class="keyword">function</span> jac = jacobian(x,auxdata)
  jac = [ -0.001352*x(1) - 0.0001906*x(2) + 0.0001014*x(3) + 0.000766, <span class="keyword">...</span>
          -0.0001906*x(1) - 0.001042*x(2) - 0.0001802*x(3) + 0.0000342, <span class="keyword">...</span>
           0.0001014*x(1) - 0.0001802*x(2) - 0.000588*x(3) - 0.000189, <span class="keyword">...</span>
           1 ; 1, 1, 1, -1 ] ;
  jac = sparse(jac) ;
<span class="keyword">end</span>

<span class="keyword">function</span> jac = jacobianstructure(auxdata)
  jac = sparse(ones(2,4)) ;
<span class="keyword">end</span>

<span class="keyword">function</span> H = hessian(x, sigma, lambda, auxdata)
  H1 = [ 0.01066 0       0       0 ; <span class="keyword">...</span>
         0       0.01778 0       0 ; <span class="keyword">...</span>
         0       0       0.01482 0 ; <span class="keyword">...</span>
         0       0       0       0 ] ;
  H2 = [ -0.1352e-2,          0,         0, 0 ; <span class="keyword">...</span>
         -0.1906e-3, -0.1042e-2,         0, 0 ; <span class="keyword">...</span>
          0.0001014, -0.1802e-3, -0.588e-3, 0 ; <span class="keyword">...</span>
          0,                  0,         0, 0 ] ;
  H = sparse(sigma*H1 + lambda(1)*H2) ;
<span class="keyword">end</span>

<span class="keyword">function</span> H = hessianstructure(auxdata)
  H = sparse([ 1 0 0 0 ; 1 1 0 0 ; 1 1 1 0 ; 1 1 1 1 ]) ;
<span class="keyword">end</span>
</pre><pre class="codeoutput">Starting derivative checker for first derivatives.


No errors detected by derivative checker.

Number of nonzeros in equality constraint Jacobian...:        4
Number of nonzeros in inequality constraint Jacobian.:        4
Number of nonzeros in Lagrangian Hessian.............:       10

Total number of variables............................:        4
                     variables with only lower bounds:        0
                variables with lower and upper bounds:        3
                     variables with only upper bounds:        0
Total number of equality constraints.................:        1
Total number of inequality constraints...............:        1
        inequality constraints with only lower bounds:        1
   inequality constraints with lower and upper bounds:        0
        inequality constraints with only upper bounds:        0

   1  5.5426785e+03 1.72e+01 2.84e+02   2.6 4.21e+02    -  1.79e-03 5.23e-01f  1
   2  5.8794179e+03 1.38e-01 3.11e+01   1.1 3.11e+01   0.0 8.97e-01 1.00e+00h  1
   3  3.6697169e+03 6.15e+00 1.66e+01  -4.8 3.26e+02    -  1.31e-01 4.66e-01f  1
   4  3.4895008e+03 5.88e+00 1.54e+01   1.0 2.10e+02    -  3.65e-01 6.44e-02f  1
   5  3.1040776e+03 7.02e+00 1.45e+01   2.8 2.66e+03    -  1.15e-01 1.85e-02f  1
   6  3.1449803e+03 2.52e+00 3.54e+00   0.1 1.77e+01    -  9.35e-01 6.51e-01h  1
   7  3.1596569e+03 2.70e-01 2.35e-01   0.6 2.25e+01    -  7.62e-01 1.00e+00f  1
   8  3.1556836e+03 4.80e-02 4.95e-03  -0.8 8.56e+00    -  9.82e-01 1.00e+00f  1
   9  3.1554779e+03 7.01e-03 3.42e-03  -2.2 2.76e+00    -  9.75e-01 1.00e+00f  1
iter    objective    inf_pr   inf_du lg(mu)  ||d||  lg(rg) alpha_du alpha_pr  ls
  10  3.1553394e+03 1.62e-03 3.64e-05  -3.3 1.35e+00    -  1.00e+00 1.00e+00f  1
  11  3.1552968e+03 2.61e-04 5.97e-06  -4.0 5.42e-01    -  1.00e+00 1.00e+00h  1
  12  3.1552884e+03 1.27e-05 2.90e-07  -4.8 1.19e-01    -  1.00e+00 1.00e+00h  1
  13  3.1552879e+03 4.57e-08 2.16e-08 -10.0 6.53e-03    -  9.99e-01 9.99e-01h  1
  14  3.1552879e+03 4.79e-13 1.11e-14 -11.0 2.32e-05    -  1.00e+00 1.00e+00h  1

Number of Iterations....: 14

                                   (scaled)                 (unscaled)
Objective...............:   3.1552879266807963e+03    3.1552879266807963e+03
Dual infeasibility......:   1.1086833252081312e-14    1.1086833252081312e-14
Constraint violation....:   4.7941511871485432e-13    4.7941511871485432e-13
Complementarity.........:   3.3279556044965579e-11    3.3279556044965579e-11
Overall NLP error.......:   3.3279556044965579e-11    3.3279556044965579e-11


Number of objective function evaluations             = 15
Number of objective gradient evaluations             = 15
Number of equality constraint evaluations            = 15
Number of inequality constraint evaluations          = 15
Number of equality constraint Jacobian evaluations   = 15
Number of inequality constraint Jacobian evaluations = 15
Number of Lagrangian Hessian evaluations             = 14
Total CPU secs in IPOPT (w/o function evaluations)   =      0.102
Total CPU secs in NLP function evaluations           =      0.128

EXIT: Optimal Solution Found.

x =

  Columns 1 through 3

  50.000000000000000  75.485880737743315  93.262254407672359

  Column 4

   8.748134655769416

</pre><p class="footer"><br><a href="https://www.mathworks.com/products/matlab/">Published with MATLAB&reg; R2020a</a><br></p></div><!--
##### SOURCE BEGIN #####

%#  NLP written by GAMS Convert at 06/20/02 11:29:54
%#  
%#  Equation counts
%#     Total       E       G       L       N       X
%#         3       2       1       0       0       0
%#  
%#  Variable counts
%#                 x       b       i     s1s     s2s      sc      si
%#     Total    cont  binary integer    sos1    sos2   scont    sint
%#         5       5       0       0       0       0       0       0
%#  FX     0       0       0       0       0       0       0       0
%#  
%#  Nonzero counts
%#     Total   const      NL     DLL
%#        12       6       6       0
%# 
%#  Reformualtion has removed 1 variable and 1 equation
%
%
%var x1 := 50, >= 50, <= 200;
%var x2 := 37.5, >= 37.5, <= 150;
%var x3 := 45, >= 45, <= 180;
%var x4;
%
%minimize obj: 0.00533*x1^2 + 11.669*x1 + 0.00889*x2^2 + 10.333*x2 + 0.00741*x3^
%              2 + 10.833*x3 + 653.1;
%
%subject to
%
%e2:  - (0.01*(0.0676*x1*x1 + 0.00953*x1*x2 - 0.00507*x1*x3 + 0.00953*x2*x1 + 
%    0.0521*x2*x2 + 0.00901*x2*x3 - 0.00507*x3*x1 + 0.00901*x3*x2 + 0.0294*x3*x3
%    ) - 0.000766*x1 - 3.42e-5*x2 + 0.000189*x3) + x4 = 0.040357;
%
%e3:    x1 + x2 + x3 - x4 >= 210;

function test_ipopt

  auxdata = {} ;

  options.lb = [ 50, 37.5, 45, -Inf ] ;  % Lower bound on the variables.
  options.ub = [ 200, 150, 180, Inf ] ;  % Upper bound on the variables.

  % The constraint functions are bounded to zero
  options.cl = [ 0, 0 ]; %  constraints
  options.cu = [ 0, Inf ];
  
  % Set up the auxiliary data.
  options.auxdata = auxdata ;
  
  % Set the IPOPT options.
  options.ipopt.jac_d_constant   = 'no';
  options.ipopt.hessian_constant = 'no';
  options.ipopt.mu_strategy      = 'adaptive';
  options.ipopt.max_iter         = 400;
  options.ipopt.tol              = 1e-10;
  
  % The callback functions.
  funcs.objective         = @objective;
  funcs.constraints       = @constraints;
  funcs.gradient          = @gradient;
  funcs.jacobian          = @jacobian;
  funcs.jacobianstructure = @jacobianstructure;
  if true
    funcs.hessian           = @hessian;
    funcs.hessianstructure  = @hessianstructure;
    options.ipopt.derivative_test = 'second-order';
  else
    options.ipopt.hessian_approximation      = 'limited-memory';
    %options.ipopt.limited_memory_update_type = 'bfgs' ; % {bfgs}, sr1 = 6; % {6}
    %options.ipopt.limited_memory_update_type = 'sr1' ;
    options.ipopt.limited_memory_update_type = 'bfgs' ; % {bfgs}, sr1 = 6; % {6}
  end

  % Run IPOPT.
  x0 = [50, 37.5, 45, 0] ; 

  tic
  [x, info] = ipopt_auxdata(x0,funcs,options);
  elapsed = toc ;

  info;

  x

end

%%
% map the indices with the corresponding index in the spase matrix
function f = objective(x,auxdata)
  f = 0.00533*x(1)^2 + 11.669*x(1) + ...
      0.00889*x(2)^2 + 10.333*x(2) + ...
      0.00741*x(3)^2 + 10.833*x(3) + 653.1 ;
end

%% 
% map the indices with the corresponding index in the spase matrix
function g = gradient(x,auxdata)
  g = [ 0.01066*x(1) + 11.669, 0.01778*x(2) + 10.333, 0.01482*x(3) + 10.833, 0 ] ;
end

function f = constraints(x,auxdata)
  f = zeros(2,1) ;
  f(1) = - (0.01*(0.0676*x(1)^2 + 0.00953*x(1)*x(2) - 0.00507*x(1)*x(3) + ...
                  0.00953*x(2)*x(1) + 0.0521*x(2)^2 + 0.00901*x(2)*x(3) - ...
                  0.00507*x(3)*x(1) + 0.00901*x(3)*x(2) + 0.0294*x(3)*x(3) ) ...
         - 0.000766*x(1) - 3.42e-5*x(2) + 0.000189*x(3)) + x(4) - 0.040357 ; % = 0
  f(2) = x(1) + x(2) + x(3) - x(4) - 210 ; % >= 0
end

function jac = jacobian(x,auxdata)
  jac = [ -0.001352*x(1) - 0.0001906*x(2) + 0.0001014*x(3) + 0.000766, ...
          -0.0001906*x(1) - 0.001042*x(2) - 0.0001802*x(3) + 0.0000342, ...
           0.0001014*x(1) - 0.0001802*x(2) - 0.000588*x(3) - 0.000189, ...
           1 ; 1, 1, 1, -1 ] ;
  jac = sparse(jac) ;
end

function jac = jacobianstructure(auxdata)
  jac = sparse(ones(2,4)) ;
end

function H = hessian(x, sigma, lambda, auxdata)
  H1 = [ 0.01066 0       0       0 ; ...
         0       0.01778 0       0 ; ...
         0       0       0.01482 0 ; ...
         0       0       0       0 ] ;
  H2 = [ -0.1352e-2,          0,         0, 0 ; ...
         -0.1906e-3, -0.1042e-2,         0, 0 ; ...
          0.0001014, -0.1802e-3, -0.588e-3, 0 ; ...
          0,                  0,         0, 0 ] ;
  H = sparse(sigma*H1 + lambda(1)*H2) ;
end

function H = hessianstructure(auxdata)
  H = sparse([ 1 0 0 0 ; 1 1 0 0 ; 1 1 1 0 ; 1 1 1 1 ]) ;
end

##### SOURCE END #####
--></body></html>